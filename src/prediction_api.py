#!/usr/bin/env python3
"""
YouTube Video Performance Prediction API
Updated to work with new CTR, RQS, and Views models
"""

import os
import sys
import json
import warnings
import joblib
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Union
from datetime import datetime
import ast
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn

# Suppress warnings
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')
warnings.filterwarnings('ignore', message='.*sklearn.*')

class YouTubePredictionSystem:
    """ML-powered prediction system for YouTube video performance using new models"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_lists = {}
        self.baseline_models = {}
        self.tfidf_vectorizers = {}
        self.svd_models = {}
        self.load_models()
        
    def load_models(self):
        """Load all trained ML models, scalers, and feature lists"""
        # Get models directory - now in Youtube_project/models
        script_dir = Path(__file__).parent
        models_dir = script_dir.parent / "models"  # Changed from extracted_data/models
        
        print("üîÑ Loading ML models...")
        print(f"üìÅ Models directory: {models_dir.absolute()}")
        
        if not models_dir.exists():
            raise FileNotFoundError(f"Models directory not found: {models_dir.absolute()}")
        
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                
                # Load CTR models (baseline + residual pattern)
                if (models_dir / "ctr_model.joblib").exists():
                    self.models['ctr'] = joblib.load(models_dir / "ctr_model.joblib")
                    print("‚úÖ CTR model loaded")
                
                if (models_dir / "ctr_baseline.joblib").exists():
                    self.baseline_models['ctr'] = joblib.load(models_dir / "ctr_baseline.joblib")
                    print("‚úÖ CTR baseline loaded")
                
                if (models_dir / "ctr_features.joblib").exists():
                    self.feature_lists['ctr'] = joblib.load(models_dir / "ctr_features.joblib")
                    print(f"   CTR expects {len(self.feature_lists['ctr'])} features")
                
                if (models_dir / "ctr_baseline_features.joblib").exists():
                    self.feature_lists['ctr_baseline'] = joblib.load(models_dir / "ctr_baseline_features.joblib")
                
                # Load RQS model
                if (models_dir / "rqs_model.joblib").exists():
                    self.models['rqs'] = joblib.load(models_dir / "rqs_model.joblib")
                    print("‚úÖ RQS model loaded")
                
                if (models_dir / "rqs_features.joblib").exists():
                    self.feature_lists['rqs'] = joblib.load(models_dir / "rqs_features.joblib")
                    print(f"   RQS expects {len(self.feature_lists['rqs'])} features")
                
                if (models_dir / "rqs_slice_stats.json").exists():
                    with open(models_dir / "rqs_slice_stats.json", 'r') as f:
                        self.rqs_slice_stats = json.load(f)
                    print("‚úÖ RQS slice stats loaded")
                
                # Load Views models (baseline + residual pattern)
                if (models_dir / "views_residual_model.joblib").exists():
                    self.models['views'] = joblib.load(models_dir / "views_residual_model.joblib")
                    print("‚úÖ Views residual model loaded")
                
                if (models_dir / "views_baseline_model.joblib").exists():
                    self.baseline_models['views'] = joblib.load(models_dir / "views_baseline_model.joblib")
                    print("‚úÖ Views baseline loaded")
                
                if (models_dir / "views_residual_scaler.joblib").exists():
                    self.scalers['views'] = joblib.load(models_dir / "views_residual_scaler.joblib")
                    print("‚úÖ Views scaler loaded")
                
                if (models_dir / "views_residual_features.joblib").exists():
                    self.feature_lists['views'] = joblib.load(models_dir / "views_residual_features.joblib")
                    print(f"   Views expects {len(self.feature_lists['views'])} features")
                
                if (models_dir / "views_baseline_features.joblib").exists():
                    self.feature_lists['views_baseline'] = joblib.load(models_dir / "views_baseline_features.joblib")
                
                print(f"üéØ Total models loaded: {len(self.models)}")
                print(f"üéØ Total baseline models: {len(self.baseline_models)}")
                
        except Exception as e:
            print(f"‚ùå Error loading models: {e}")
            raise
    
    def generate_tfidf_embeddings(self, text: str, prefix: str, n_components: int = 30) -> np.ndarray:
        """
        Generate TF-IDF embeddings similar to training.
        Note: In production, you should save and load the fitted TF-IDF and SVD models.
        This is a simplified version that creates zero embeddings as placeholder.
        """
        # In production, load the saved TF-IDF and SVD models
        # For now, return zero embeddings of the right size
        return np.zeros(n_components)
    
    def prepare_features_for_ctr(self, video_data: Dict) -> pd.DataFrame:
        """Prepare features matching CTR model expectations"""
        if 'ctr' not in self.feature_lists:
            raise ValueError("CTR feature list not loaded")
        
        feature_cols = self.feature_lists['ctr']
        features = {}
        
        # Create all required features with defaults
        for col in feature_cols:
            if col.startswith('title_embed_'):
                # Title embeddings (would use saved TF-IDF model in production)
                features[col] = 0.0
            elif col.startswith('description_embed_'):
                features[col] = 0.0
            elif col.startswith('tags_embed_'):
                features[col] = 0.0
            elif col.startswith('thumb_text_embed_'):
                features[col] = 0.0
            elif col.startswith('genre_'):
                # Genre one-hot encoding
                genre = video_data.get('genre', 'unknown')
                features[col] = 1.0 if col == f'genre_{genre}' else 0.0
            elif col in video_data:
                features[col] = float(video_data[col])
            else:
                # Default values for other features
                if 'duration' in col:
                    features[col] = 300.0
                elif 'brightness' in col or 'avg_' in col:
                    features[col] = 128.0
                elif 'face' in col:
                    features[col] = 0.1
                else:
                    features[col] = 0.0
        
        return pd.DataFrame([features])[feature_cols]  # Ensure correct column order
    
    def prepare_features_for_rqs(self, video_data: Dict) -> pd.DataFrame:
        """Prepare features matching RQS model expectations"""
        if 'rqs' not in self.feature_lists:
            raise ValueError("RQS feature list not loaded")
        
        feature_cols = self.feature_lists['rqs']
        features = {}
        
        # Similar to CTR but for RQS columns
        for col in feature_cols:
            if col.startswith('title_embed_'):
                features[col] = 0.0
            elif col.startswith('description_embed_'):
                features[col] = 0.0
            elif col.startswith('tags_embed_'):
                features[col] = 0.0
            elif col.startswith('thumb_text_embed_'):
                features[col] = 0.0
            elif col.startswith('genre_'):
                genre = video_data.get('genre', 'unknown')
                features[col] = 1.0 if col == f'genre_{genre}' else 0.0
            elif col in video_data:
                features[col] = float(video_data[col])
            else:
                # Default values
                if 'duration' in col:
                    features[col] = 300.0
                elif 'brightness' in col or 'avg_' in col:
                    features[col] = 128.0
                else:
                    features[col] = 0.0
        
        return pd.DataFrame([features])[feature_cols]
    
    def prepare_baseline_features(self, video_data: Dict, model_type: str) -> pd.DataFrame:
        """Prepare baseline features (log_age, log_subs, genre)"""
        feature_list_key = f'{model_type}_baseline'
        if feature_list_key not in self.feature_lists:
            # Default baseline features
            feature_cols = ['log_age', 'log_subs'] + [f'genre_{g}' for g in 
                          ['unknown', 'gaming', 'education_science', 'challenge_stunts', 'catholic', 'kids_family']]
        else:
            feature_cols = self.feature_lists[feature_list_key]
        
        features = {}
        
        # Calculate log features
        features['log_subs'] = np.log1p(video_data.get('channel_subscriber_count', 1000))
        features['log_age'] = np.log1p(video_data.get('age_days', 0))
        
        # Add log_duration if needed
        if 'log_duration' in feature_cols:
            features['log_duration'] = np.log1p(video_data.get('duration_seconds', 300))
        
        # Genre encoding
        genre = video_data.get('genre', 'unknown')
        for col in feature_cols:
            if col.startswith('genre_'):
                features[col] = 1.0 if col == f'genre_{genre}' else 0.0
            elif col not in features:
                features[col] = 0.0
        
        return pd.DataFrame([features])[feature_cols]
    
    def predict_ctr(self, video_data: Dict) -> float:
        """Predict CTR using baseline + residual model"""
        if 'ctr' not in self.models:
            # Fallback
            return 0.05
        
        try:
            # Prepare features for residual model
            X_residual = self.prepare_features_for_ctr(video_data)
            
            # Get residual prediction
            if hasattr(self.models['ctr'], 'named_steps'):
                # It's a pipeline
                residual_pred = self.models['ctr'].predict(X_residual)[0]
            else:
                residual_pred = self.models['ctr'].predict(X_residual.values)[0]
            
            # Get baseline prediction if available
            if 'ctr' in self.baseline_models:
                X_baseline = self.prepare_baseline_features(video_data, 'ctr')
                baseline_pred = self.baseline_models['ctr'].predict(X_baseline)[0]
                
                # CTR is baseline + residual
                ctr_log = baseline_pred + residual_pred
            else:
                ctr_log = residual_pred
            
            # Convert from log scale
            ctr = np.expm1(ctr_log) if ctr_log > 0 else ctr_log
            
            # Bound between 0 and 1
            return np.clip(ctr, 0.0, 1.0)
            
        except Exception as e:
            print(f"CTR prediction error: {e}")
            return 0.05
    
    def predict_rqs(self, video_data: Dict) -> float:
        """Predict RQS (0-100 score)"""
        if 'rqs' not in self.models:
            return 50.0
        
        try:
            # Prepare features
            X_rqs = self.prepare_features_for_rqs(video_data)
            
            # Get prediction
            if hasattr(self.models['rqs'], 'named_steps'):
                # It's a pipeline
                rqs_pred = self.models['rqs'].predict(X_rqs)[0]
            else:
                rqs_pred = self.models['rqs'].predict(X_rqs.values)[0]
            
            # Bound between 0 and 100
            return np.clip(rqs_pred, 0.0, 100.0)
            
        except Exception as e:
            print(f"RQS prediction error: {e}")
            return 50.0
    
    def predict_views(self, ctr_pred: float, rqs_pred: float, video_data: Dict) -> int:
        """Predict views using CTR and RQS predictions"""
        if 'views' not in self.models:
            # Simple fallback
            subs = video_data.get('channel_subscriber_count', 1000)
            return int(subs * ctr_pred)
        
        try:
            # Prepare baseline features
            X_baseline = self.prepare_baseline_features(video_data, 'views')
            
            # Get baseline prediction
            if 'views' in self.baseline_models:
                baseline_pred = self.baseline_models['views'].predict(X_baseline)[0]
            else:
                baseline_pred = np.log1p(video_data.get('channel_subscriber_count', 1000) * 0.1)
            
            # Prepare residual features (using CTR and RQS predictions)
            if 'views' in self.feature_lists:
                feature_cols = self.feature_lists['views']
                features = {}
                
                for col in feature_cols:
                    if 'ctr_pred' in col:
                        if 'sq' in col:
                            features[col] = ctr_pred ** 2
                        elif 'log' in col:
                            features[col] = np.log1p(max(0, ctr_pred))
                        else:
                            features[col] = ctr_pred
                    elif 'rqs_pred' in col:
                        if 'sq' in col:
                            features[col] = (rqs_pred / 100) ** 2
                        elif 'sigmoid' in col:
                            features[col] = 1 / (1 + np.exp(-(rqs_pred - 50) / 10))
                        else:
                            features[col] = rqs_pred
                    elif 'interaction' in col:
                        features[col] = ctr_pred * (rqs_pred / 100)
                    elif 'product' in col:
                        features[col] = np.sqrt(max(0, ctr_pred * rqs_pred / 100))
                    elif col.startswith('genre_'):
                        genre = video_data.get('genre', 'unknown')
                        features[col] = 1.0 if col == f'genre_{genre}' else 0.0
                    elif 'log_age' in col:
                        if 'sq' in col:
                            features[col] = np.log1p(video_data.get('age_days', 0)) ** 2
                        else:
                            features[col] = np.log1p(video_data.get('age_days', 0))
                    elif 'log_subs' in col:
                        features[col] = np.log1p(video_data.get('channel_subscriber_count', 1000))
                    else:
                        features[col] = 0.0
                
                X_residual = pd.DataFrame([features])[feature_cols]
            else:
                # Fallback feature structure
                X_residual = pd.DataFrame([{
                    'ctr_pred': ctr_pred,
                    'ctr_pred_sq': ctr_pred ** 2,
                    'rqs_pred': rqs_pred,
                    'rqs_pred_sq': (rqs_pred / 100) ** 2,
                    'interaction': ctr_pred * rqs_pred / 100,
                    'log_age': np.log1p(video_data.get('age_days', 0))
                }])
            
            # Scale features if scaler available
            if 'views' in self.scalers:
                X_residual_scaled = self.scalers['views'].transform(X_residual)
                residual_pred = self.models['views'].predict(X_residual_scaled)[0]
            else:
                residual_pred = self.models['views'].predict(X_residual)[0]
            
            # Combine baseline + residual
            views_log = baseline_pred + residual_pred
            
            # Convert from log scale
            views = np.expm1(views_log)
            
            return max(int(views), 10)
            
        except Exception as e:
            print(f"Views prediction error: {e}")
            subs = video_data.get('channel_subscriber_count', 1000)
            return int(subs * ctr_pred)
    
    def predict_performance(self, 
                          title: str,
                          genre: str,
                          subscriber_count: int,
                          thumbnail_data: Optional[bytes] = None,
                          video_data: Optional[Dict] = None) -> Dict:
        """Main prediction method using the new model pipeline"""
        
        try:
            print(f"üöÄ Starting prediction: '{title[:30]}...'")
            
            # Prepare video data
            if video_data is None:
                video_data = {}
            
            video_data.update({
                'title': title,
                'genre': genre,
                'channel_subscriber_count': subscriber_count,
                'age_days': 0,  # New video
                'duration_seconds': video_data.get('duration_seconds', 300),
            })
            
            # Step 1: Predict CTR
            ctr_pred = self.predict_ctr(video_data)
            print(f"üìä CTR predicted: {ctr_pred:.4f}")
            
            # Step 2: Predict RQS
            rqs_pred = self.predict_rqs(video_data)
            print(f"üìà RQS predicted: {rqs_pred:.1f}")
            
            # Step 3: Predict Views using CTR and RQS
            views_pred = self.predict_views(ctr_pred, rqs_pred, video_data)
            print(f"üëÅÔ∏è Views predicted: {views_pred:,}")
            
            return {
                'predicted_views': views_pred,
                'predicted_rqs': rqs_pred,
                'predicted_ctr': ctr_pred,
                'confidence_score': 0.85,
                'model_version': '3.0',
                'models_used': list(self.models.keys()),
                'prediction_flow': 'CTR ‚Üí RQS ‚Üí Views'
            }
            
        except Exception as e:
            print(f"‚ùå Prediction error: {e}")
            import traceback
            traceback.print_exc()
            
            # Fallback predictions
            return {
                'predicted_views': int(subscriber_count * 0.05),
                'predicted_rqs': 50.0,
                'predicted_ctr': 0.03,
                'confidence_score': 0.3,
                'error': str(e)
            }

# Initialize prediction system
predictor = YouTubePredictionSystem()

# FastAPI app
app = FastAPI(title="YouTube Performance Predictor", version="3.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.post("/api/predict")
async def predict_video_performance(
    title: str = Form(...),
    genre: str = Form(...),
    subscriber_count: int = Form(...),
    thumbnail: Optional[UploadFile] = File(None),
    tags: Optional[str] = Form(None),
    description: Optional[str] = Form(None),
    duration_seconds: Optional[int] = Form(None)
):
    """Predict video performance using new ML models"""
    
    try:
        # Validate genre
        valid_genres = ['gaming', 'education_science', 'challenge_stunts', 'catholic', 
                       'kids_family', 'unknown']
        if genre not in valid_genres:
            genre = 'unknown'
        
        # Prepare video data
        video_data = {
            'duration_seconds': duration_seconds or 300,
            'age_days': 0
        }
        
        if tags:
            try:
                video_data['tags'] = ast.literal_eval(tags) if tags.startswith('[') else tags.split(',')
            except:
                video_data['tags'] = tags.split(',')
        
        if description:
            video_data['description'] = description
        
        # Process thumbnail if provided
        thumbnail_data = None
        if thumbnail:
            thumbnail_data = await thumbnail.read()
        
        # Get predictions
        predictions = predictor.predict_performance(
            title=title,
            genre=genre,
            subscriber_count=subscriber_count,
            thumbnail_data=thumbnail_data,
            video_data=video_data
        )
        
        # Add metadata
        predictions['input_data'] = {
            'title': title,
            'genre': genre,
            'subscriber_count': subscriber_count,
            'has_thumbnail': thumbnail is not None,
            'prediction_date': datetime.now().isoformat()
        }
        
        return JSONResponse(content=predictions)
        
    except Exception as e:
        print(f"‚ùå API error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "service": "YouTube ML Prediction API",
        "version": "3.0",
        "status": "active",
        "models": {
            "ctr": "ctr" in predictor.models,
            "rqs": "rqs" in predictor.models,
            "views": "views" in predictor.models
        }
    }

@app.get("/api/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "models_loaded": len(predictor.models),
        "baseline_models": len(predictor.baseline_models),
        "timestamp": datetime.now().isoformat()
    }

if __name__ == "__main__":
    print("üöÄ Starting YouTube Performance Prediction API v3.0...")
    print(f"üìä Models loaded: {list(predictor.models.keys())}")
    print(f"üìä Baseline models: {list(predictor.baseline_models.keys())}")
    print("üîÆ Ready for predictions!")
    print("üìñ API docs: http://localhost:8002/docs")
    
    uvicorn.run(app, host="0.0.0.0", port=8002, log_level="info")