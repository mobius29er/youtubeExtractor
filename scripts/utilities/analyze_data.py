#!/usr/bin/env python3
import os
"""
YouTube Data Quality Analysis
Analyzes the extracted YouTube data for accuracy and completeness
"""

import pandas as pd
import numpy as np
from datetime import datetime

def analyze_youtube_data():
    """Comprehensive analysis of extracted YouTube data"""
    
    print("üîç YOUTUBE DATA QUALITY ANALYSIS")
    print("=" * 50)
    
    # Load the data
    df = pd.read_csv('extracted_data/api_only_ml_SAFE.csv') if os.path.exists('extracted_data/api_only_ml_SAFE.csv') else pd.read_csv('extracted_data/api_only_ml_dataset.csv')
    
    # Basic statistics
    print(f"üìä BASIC STATISTICS:")
    print(f"   ‚Ä¢ Total videos extracted: {len(df):,}")
    print(f"   ‚Ä¢ Unique channels: {df['channel_name'].nunique()}")
    print(f"   ‚Ä¢ Date range: {df['published_at'].min()} to {df['published_at'].max()}")
    print(f"   ‚Ä¢ Missing values: {df.isnull().sum().sum()}")
    
    # Channel breakdown
    print(f"\nüìà CHANNEL DISTRIBUTION:")
    channel_counts = df['channel_name'].value_counts()
    for channel, count in channel_counts.items():
        print(f"   ‚Ä¢ {channel}: {count} videos")
    
    # View statistics
    print(f"\nüëÄ VIEW STATISTICS:")
    total_views = df['view_count'].sum()
    avg_views = df['view_count'].mean()
    median_views = df['view_count'].median()
    
    print(f"   ‚Ä¢ Total views: {total_views:,.0f}")
    print(f"   ‚Ä¢ Average views per video: {avg_views:,.0f}")
    print(f"   ‚Ä¢ Median views: {median_views:,.0f}")
    
    # Top performers
    print(f"\nüèÜ TOP 5 MOST VIEWED VIDEOS:")
    top_videos = df.nlargest(5, 'view_count')
    for i, (_, row) in enumerate(top_videos.iterrows(), 1):
        title = row['title'][:60] + '...' if len(row['title']) > 60 else row['title']
        print(f"   {i}. {row['view_count']:,.0f} views - {title}")
        print(f"      Channel: {row['channel_name']}")
    
    # Channel performance
    print(f"\nüéØ CHANNEL PERFORMANCE (by total views):")
    channel_stats = df.groupby('channel_name').agg({
        'view_count': ['sum', 'mean'],
        'like_count': 'sum',
        'comment_count': 'sum'
    }).round(0)
    
    channel_stats.columns = ['total_views', 'avg_views', 'total_likes', 'total_comments']
    channel_stats = channel_stats.sort_values('total_views', ascending=False)
    
    for channel, stats in channel_stats.iterrows():
        print(f"   ‚Ä¢ {channel}:")
        print(f"     - Total views: {stats['total_views']:,.0f}")
        print(f"     - Avg views/video: {stats['avg_views']:,.0f}")
        print(f"     - Total likes: {stats['total_likes']:,.0f}")
    
    # Data quality assessment
    print(f"\n‚úÖ DATA QUALITY ASSESSMENT:")
    
    # Check for complete records
    complete_records = len(df.dropna())
    completeness = (complete_records / len(df)) * 100
    print(f"   ‚Ä¢ Complete records: {complete_records}/{len(df)} ({completeness:.1f}%)")
    
    # Check data consistency
    consistent_channel_counts = all(count == 40 for count in channel_counts.values())
    print(f"   ‚Ä¢ Consistent channel sampling: {'‚úÖ Yes' if consistent_channel_counts else '‚ùå No'}")
    
    # Check for duplicate videos
    duplicates = df['video_id'].duplicated().sum()
    print(f"   ‚Ä¢ Duplicate videos: {duplicates} ({'‚úÖ None' if duplicates == 0 else '‚ö†Ô∏è Found'})")
    
    # Overall health score

def safe_int(value, default=0):
    """Safely convert value to int"""
    if isinstance(value, int):
                return value
    if isinstance(value, str) and value.isdigit():
        return int(value)
    return default

def safe_float(value, default=0.0):
    """Safely convert value to float"""
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        try:
            return float(value)
        except ValueError:
            return default
    return default
    health_factors = [
        completeness > 95,  # High completeness
        consistent_channel_counts,  # Consistent sampling
        duplicates == 0,  # No duplicates
        len(df) > 500,  # Good volume
        df['channel_name'].nunique() >= 10  # Good diversity
    ]
    
    health_score = sum(health_factors) / len(health_factors) * 100
    
    print(f"\nüéâ OVERALL DATA HEALTH SCORE: {health_score:.0f}%")
    
    if health_score >= 80:
        print("   ‚úÖ EXCELLENT - Data is high quality and ready for analysis!")
    elif health_score >= 60:
        print("   ‚ö†Ô∏è  GOOD - Data is usable with minor issues")
    else:
        print("   ‚ùå POOR - Data has significant quality issues")
    
    return df, health_score

if __name__ == "__main__":
    df, score = analyze_youtube_data()
